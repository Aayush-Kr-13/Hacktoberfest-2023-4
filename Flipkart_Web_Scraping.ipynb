HTML Page Read and Upload
In [4]:
# Import useful libraries and classes.
from urllib.request import urlopen as uReq
from bs4 import BeautifulSoup as soup
from dis import dis
from xmlrpc.client import Boolean
import pandas as pd
In [5]:
battery = []
model = []
price = []
discount = []
camera = []
ram = []
display = []
In [6]:
class Source:
    containers = []
    def __init__(self,containers):
        self.containers = containers

    def extract(self,):
        for container in self.containers:
            # inserting model name in the list
            model_name = container.findAll("div", {"class": "_4rR01T"})
            model.append(model_name[0].text.strip())
            # inserting price and discount similarly
            price_model = container.findAll("div", {"class": "_30jeq3 _1_WHN1"})
            price.append(price_model[0].text.strip())

            info = container.findAll("li", {"class": "rgWa7D"}) 
            ram.append(info[0].text.strip().split(' ', 1)[0])
            display.append(info[1].text.strip().split(' ', 1)[0])
            camera.append(info[2].text.strip())
            battery.append(info[3].text.strip().split(' ', 1)[0])



            discount_percent = container.findAll("div", {"class": "_3Ay6Sb"})
            # discount.append(discount_percent[0].text.strip())
            if discount_percent == []:
                discount.append("Null")
            else:
                discount.append(discount_percent[0].text)
In [7]:
# html page upload and read in web_page variable.
my_url = "https://www.flipkart.com/search?p%5B%5D=facets.brand%255B%255D%3DSamsung&sid=tyy%2F4io&sort=recency_desc&wid=1.productCard.PMU_V2_1&page=1"

for i in range(1,11):     # to check change the variable to 3 or 4
    my_url = my_url[:-1] + f'{i}'
    
    web_page = uReq(my_url)
    page_html = web_page.read()
    # html parser. It is to beautify the HTML code.
    page_soup = soup(page_html)
    # page_soup

    # read class attribute from web page in containers variable.
    # Print the length of containers.   
    containers = page_soup.findAll("div", {"class": "_2kHMtA"})  
    print(len(containers))
    cs1 = Source(containers)
    cs1.extract()
    ############################################################################################
    
   
24
24
24
24
24
24
24
24
24
24
In [8]:

for container in containers:
    # inserting model name in the list
    model_name = container.findAll("div", {"class": "_4rR01T"})
    model.append(model_name[0].text.strip())
    # inserting price and discount similarly
    price_model = container.findAll("div", {"class": "_30jeq3 _1_WHN1"})
    price.append(price_model[0].text.strip())

    info = container.findAll("li", {"class": "rgWa7D"}) 
    ram.append(info[0].text.strip().split(' ', 1)[0])
    display.append(info[1].text.strip().split(' ', 1)[0])
    camera.append(info[2].text.strip())
    battery.append(info[3].text.strip().split(' ', 1)[0])



    discount_percent = container.findAll("div", {"class": "_3Ay6Sb"})
    # discount.append(discount_percent[0].text.strip())
    if discount_percent == []:
        discount.append("Null")
    else:
        discount.append(discount_percent[0].text)
In [9]:
df = pd.DataFrame(list(zip(model, battery, camera,display,ram ,price, discount)), columns=["Model", "Battery(mah)", "Camera","Display Size", "Ram", "Price", "Discount"])
df

file_name = "Flipkart_Samsung.xlsx"

df.to_excel(file_name)
